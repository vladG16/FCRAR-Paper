
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>FCRAR 2025 Submission â€” Husky Robot Navigation</title>
  <style>
    body { font-family: Arial, sans-serif; line-height: 1.6; margin: 40px; max-width: 800px; }
    h1 { color: #333366; }
    h2 { color: #555; }
    a { color: #0066cc; }
  </style>
</head>
<body>
  <h1>Accelerating Early-Stage Robot Navigation Development with Motion Capture and ROS</h1>
  <p><strong>Authors:</strong> Pratik Mukherjee, Daniel Granda, Vladimir Gunichev, Caleb Sanchez</p>
  <p><strong>Affiliation:</strong> Department of Ocean and Mechanical Engineering, Florida Atlantic University (FAU)</p>

  <h2>Abstract</h2>
  <p>This paper presents and validates a waypoint navigation system that integrates the OptiTrack motion capture system with ROS Noetic. Utilizing precise positioning data, we demonstrate successful navigation of the Husky A200 robot platform without the need for onboard sensors, relying solely on external camera positioning and odometry.</p>

  <h2>Methodology</h2>
  <p>The Husky robot was guided using waypoints recorded via a joystick, navigating a predefined path using pose data streamed from OptiTrack into ROS. Our experiments confirmed that external motion capture is effective for early-stage testing of navigation strategies.</p>

  <h2>Conclusion</h2>
  <p>This method greatly accelerates development by reducing complexity and allowing for sensor-free validation. Future work will include SLAM integration and deployment for real-world tasks like power system inspections.</p>

  <p><a href="FCRAR_Submission_Husky.pdf" target="_blank">ðŸ“„ Download Full Paper (PDF)</a></p>
</body>
</html>
